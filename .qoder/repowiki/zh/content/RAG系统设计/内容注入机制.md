# 内容注入机制

<cite>
**本文档中引用的文件**  
- [ChatContentInjector.java](file://ai/src/main/java/com/shuanglin/bot/langchain4j/rag/contentInjector/ChatContentInjector.java)
- [AugmentConfig.java](file://ai/src/main/java/com/shuanglin/bot/langchain4j/rag/AugmentConfig.java)
- [system-message.txt](file://ai/src/main/resources/prompt/system-message.txt)
- [kgKnowlage.md](file://ai/src/main/resources/prompt/kgKnowlage.md)
- [user-session-message.md](file://ai/src/main/resources/prompt/user-session-message.md)
</cite>

## 目录
1. [引言](#引言)
2. [核心组件分析](#核心组件分析)
3. [工作流程与机制](#工作流程与机制)
4. [提示模板应用过程](#提示模板应用过程)
5. [内容拼接与上下文连贯性](#内容拼接与上下文连贯性)
6. [实际注入示例](#实际注入示例)
7. [安全与一致性设计考量](#安全与一致性设计考量)
8. [结论](#结论)

## 引言
`ChatContentInjector` 是检索增强生成（RAG）流程中的关键组件，负责将从向量数据库中检索到的相关内容注入到大语言模型（LLM）的提示（Prompt）中。作为 `ContentInjector` 接口的具体实现，它通过结构化的方式整合用户查询与检索结果，确保LLM在生成响应时能够基于准确、相关的上下文信息。本文档深入分析其工作机制、模板应用、内容拼接策略以及在系统安全与对话一致性方面的设计。

## 核心组件分析

`ChatContentInjector` 类是 `ContentInjector` 接口的实现，其主要职责是处理检索到的 `Content` 列表，并将其与原始用户消息结合，构建一个适合LLM理解的系统消息。

该类通过 `@Resource(name = "storePromptTemplate")` 注解注入了一个名为 `storePromptTemplate` 的 `PromptTemplate` 对象，这是构建最终提示的核心模板。其核心方法 `inject` 接收两个参数：一个 `Content` 对象列表（包含检索结果）和一个 `ChatMessage` 对象（代表原始用户消息）。

**组件来源**
- [ChatContentInjector.java](file://ai/src/main/java/com/shuanglin/bot/langchain4j/rag/contentInjector/ChatContentInjector.java#L17-L39)

## 工作流程与机制

`inject` 方法的工作流程如下：

1.  **空值检查**：首先检查 `contents` 列表是否为空。如果为空，则直接返回原始的 `chatMessage`，不进行任何注入操作。
2.  **元数据提取**：从 `contents` 列表的第一个元素中提取其 `TextSegment` 的元数据（`metadata()`），并将其转换为一个 `Map<String, Object>`。这表明系统假设所有检索到的内容共享相同的元数据结构，或者仅使用第一个内容的元数据作为上下文。
3.  **内容拼接**：使用 `StringJoiner` 将所有 `Content` 对象中的文本内容（通过 `Content::textSegment` 和 `TextSegment::text` 获取）连接成一个单一的字符串，各内容之间以换行符 `\n` 分隔。
4.  **参数映射**：将拼接后的内容字符串放入元数据 `Map` 中，键为 `"content"`。同时，将原始用户消息的文本（通过 `((UserMessage) chatMessage).singleText()` 获取）放入 `Map` 中，键为 `"userMessage"`。
5.  **模板应用**：使用 `storePromptTemplate.apply(params)` 方法，将包含 `"content"` 和 `"userMessage"` 的参数 `Map` 应用到预定义的提示模板上，生成一个 `Prompt` 对象。
6.  **消息转换**：最后，调用 `apply.toSystemMessage()` 将生成的 `Prompt` 转换为一个 `SystemMessage` 对象并返回。这表明检索到的内容被作为系统指令的一部分注入，从而在LLM的上下文中确立其权威性和指导性。

**代码来源**
- [ChatContentInjector.java](file://ai/src/main/java/com/shuanglin/bot/langchain4j/rag/contentInjector/ChatContentInjector.java#L23-L38)

## 提示模板应用过程

`storePromptTemplate` 的定义位于 `AugmentConfig.java` 文件中，其模板内容如下：

```
首先基础原则
你必须遵守中华人民共和国法律法规，不得逾越或触碰任何违法甚至损害中国形象。
你必须使用简体中文，或者繁体中文，或者粤语的俚语进行回答，取决于问题所使用语言。
你将扮演多个角色，回答符合角色设定且根据历史记录相关的回答。
回答内容尽可能符合角色设定，字数保持在200以内。
角色
{{modelName}}

角色设定
{{description}}

行为指令
{{instruction}}

历史参考
{{history}}
`
当前用户需求
{{userMessage}}
```

在 `inject` 方法的执行过程中，`params` 映射会填充以下关键参数：
- `{{content}}`：被替换为所有检索到的文本内容的拼接结果。
- `{{userMessage}}`：被替换为用户的原始查询文本。

虽然模板中定义了 `{{modelName}}`, `{{description}}`, `{{instruction}}`, 和 `{{history}}` 等占位符，但在 `ChatContentInjector` 的 `inject` 方法中，这些参数是从第一个 `Content` 的元数据中获取的。如果元数据中不包含这些键，则这些部分在最终提示中可能为空或保留占位符。这表明元数据的完整性对于生成一个功能完整的提示至关重要。

**模板来源**
- [AugmentConfig.java](file://ai/src/main/java/com/shuanglin/bot/langchain4j/rag/AugmentConfig.java#L10-L31)

## 内容拼接与上下文连贯性

`StringJoiner` 在此过程中扮演了至关重要的角色。它提供了一种高效且线程安全的方式来连接多个字符串。

通过使用 `contents.stream().map(...).collect()` 配合 `StringJoiner`，代码实现了对 `Content` 列表的流式处理。`collect(() -> new StringJoiner("\n"), StringJoiner::add, StringJoiner::merge)` 的三个参数分别定义了：
- **Supplier**：创建一个新的 `StringJoiner` 实例，指定分隔符为换行符 `\n`。
- **BiConsumer**：将每个处理后的文本添加到 `StringJoiner` 中。
- **BiConsumer**：在并行流的情况下，将两个 `StringJoiner` 的结果合并。

使用换行符作为分隔符是保持上下文连贯性的关键设计。它确保了每个检索到的文档片段在最终的提示中都是独立且可区分的，避免了不同片段的文本在连接处产生语义混淆。这种清晰的分隔有助于LLM更好地解析和理解每个信息单元，从而生成更准确的响应。

**代码来源**
- [ChatContentInjector.java](file://ai/src/main/java/com/shuanglin/bot/langchain4j/rag/contentInjector/ChatContentInjector.java#L27-L28)

## 实际注入示例

假设用户提出问题：“如何定义知识图谱中的实体？”

1.  **检索阶段**：RAG系统通过向量搜索，从知识库（如 `kgKnowlage.md`）中检索到两个相关片段：
    -   片段1：`**实体 (Entity):** 定义: 一个在时间中持续存在的、可识别的客体（物理或概念上的），是图中的“名词”。`
    -   片段2：`**核心属性:** uuid: 全局唯一标识符，代表其恒定的身份。`

2.  **注入阶段**：`ChatContentInjector` 执行 `inject` 方法：
    -   `content` 参数被拼接为：
        ```
        **实体 (Entity):** 定义: 一个在时间中持续存在的、可识别的客体（物理或概念上的），是图中的“名词”。
        **核心属性:** uuid: 全局唯一标识符，代表其恒定的身份。
        ```
    -   `userMessage` 参数为：“如何定义知识图谱中的实体？”

3.  **最终提示**：应用 `storePromptTemplate` 后，发送给LLM的系统消息将包含：
    ```
    ...
    角色
    {{modelName}}

    角色设定
    {{description}}

    行为指令
    {{instruction}}

    历史参考
    {{history}}

    当前用户需求
    如何定义知识图谱中的实体？
    ```
    其中，`...` 部分是模板的固定原则，而 `{{modelName}}`, `{{description}}` 等则由元数据填充。检索到的内容和用户问题共同构成了LLM生成答案的直接依据。

**知识库来源**
- [kgKnowlage.md](file://ai/src/main/resources/prompt/kgKnowlage.md#L10-L15)
- [user-session-message.md](file://ai/src/main/resources/prompt/user-session-message.md#L1-L13)

## 安全与一致性设计考量

`ChatContentInjector` 的设计在多个层面体现了对安全性和一致性的考量：

1.  **防止提示注入攻击**：
    -   **角色分离**：该组件明确地将检索到的内容注入到 `SystemMessage` 中，而不是 `UserMessage`。系统消息通常被视为不可变的指令，这降低了恶意用户通过构造特殊查询来篡改系统核心指令的风险。
    -   **内容沙盒化**：检索到的内容被视为“已知信息”，其作用是补充和增强回答，而非定义回答的框架。回答的框架由 `storePromptTemplate` 中的固定原则（如遵守中国法律、使用中文回答）所控制，这为LLM的输出设定了安全边界。

2.  **保持对话一致性**：
    -   **元数据驱动**：通过从检索内容中提取元数据（如 `modelName`, `description`），系统能够动态地调整LLM的角色和行为指令。这确保了LLM的响应风格和知识领域与当前对话的上下文保持一致。
    -   **结构化注入**：采用预定义的模板进行内容注入，保证了每次生成的提示都具有相同的结构和逻辑。这种一致性使得LLM的行为更加可预测，避免了因提示格式混乱而导致的输出质量下降。

**设计来源**
- [system-message.txt](file://ai/src/main/resources/prompt/system-message.txt#L1-L8)
- [ChatContentInjector.java](file://ai/src/main/java/com/shuanglin/bot/langchain4j/rag/contentInjector/ChatContentInjector.java)

## 结论
`ChatContentInjector` 是RAG流程中连接检索与生成的关键桥梁。它通过 `inject` 方法，利用 `StringJoiner` 高效拼接检索内容，并通过 `storePromptTemplate` 将内容与用户查询结构化地整合为一个 `SystemMessage`。这一过程不仅实现了知识的有效注入，其将内容置于系统消息的设计也强化了系统的安全性，防止了提示注入攻击。同时，基于元数据的动态角色设定和结构化的模板应用，确保了LLM响应的风格和准确性与对话上下文的高度一致。该组件的设计体现了对RAG系统功能性、安全性和一致性的综合考量。